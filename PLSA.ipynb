{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9171300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e8354a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_components = 10\n",
    "n_top_words = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e506721",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, _ = fetch_20newsgroups(shuffle=True, random_state=1,\n",
    "                             remove=('headers', 'footers', 'quotes'),\n",
    "                             return_X_y=True)\n",
    "data_samples = data[:n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff472856",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=n_features, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(data_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9238263",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:312: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn((\"The 'init' value, when 'init=None' and \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " PLSA: \n",
      "\n",
      "    Topic0   Topic1      Topic2      Topic3 Topic4      Topic5    Topic6  \\\n",
      "0  people  windows         god      thanks     10       space       edu   \n",
      "1     don     help        does        know     00  government      file   \n",
      "2    just   thanks       jesus        bike   sale      number       com   \n",
      "3    like    using        true  interested   time      public   program   \n",
      "4   think       hi        book        mail  power        data      soon   \n",
      "5     did  looking   christian        like     12      states       try   \n",
      "6     say     info       bible         new    new       earth    window   \n",
      "7    time    video  christians         car     15    security   problem   \n",
      "8    make      dos    religion         edu   year       water  remember   \n",
      "9    know       pc       faith       heard     30    research     files   \n",
      "\n",
      "     Topic7    Topic8   Topic9  \n",
      "0      game     drive      use  \n",
      "1      team     think     good  \n",
      "2      year      hard     just  \n",
      "3     games  software      key  \n",
      "4      play      disk     chip  \n",
      "5       win    drives      got  \n",
      "6    season     apple     like  \n",
      "7    points  computer       ll  \n",
      "8     world       mac      way  \n",
      "9  division      need  clipper  \n"
     ]
    }
   ],
   "source": [
    "nmf = NMF(n_components=n_components, random_state=1,\n",
    "          beta_loss='kullback-leibler', solver='mu', max_iter=1000, alpha=.1,\n",
    "          l1_ratio=.5).fit(tfidf)\n",
    "\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "word_dict ={}\n",
    "for topic_idx, topic in enumerate(nmf.components_):\n",
    "        top_features_ind = topic.argsort()[:-n_top_words - 1:-1]\n",
    "        top_features = [tfidf_feature_names[i] for i in top_features_ind]\n",
    "        word_dict['Topic'+str(topic_idx)] = top_features\n",
    "topics = pd.DataFrame(word_dict)\n",
    "print('\\n\\n PLSA: \\n\\n',topics.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c4de89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " LDA: \n",
      "\n",
      "      Topic0   Topic1   Topic2 Topic3   Topic4     Topic5    Topic6    Topic7  \\\n",
      "0   windows      dog      god     pp      2nd      cases      mike    assume   \n",
      "1    thanks   attack   accept     22     math         00      love      magi   \n",
      "2      file     head     read     18   ground       soon  graphics      home   \n",
      "3       edu    drive    clock     19    value        edu      hear     order   \n",
      "4       use  talking  driving     11     said       sale     heard      card   \n",
      "5     drive    human    stuff     23    leafs  condition       try     right   \n",
      "6  software    maybe   nature     26  display  effective     state       lot   \n",
      "7      mail     disk     port     55     long     asking      time  supposed   \n",
      "8      help  printer    think    van      try   consider   looking       hit   \n",
      "9      does  drivers    error     10    lunar       good      good    better   \n",
      "\n",
      "   Topic8  Topic9  \n",
      "0    just  wanted  \n",
      "1     don    1992  \n",
      "2  people      gm  \n",
      "3    like  season  \n",
      "4   think    1993  \n",
      "5    know  wouldn  \n",
      "6    good      vs  \n",
      "7     god    john  \n",
      "8    time      30  \n",
      "9     new   price  \n"
     ]
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(\n",
    "    n_components=n_components, \n",
    "    max_iter=5, \n",
    "    learning_method='online', \n",
    "    learning_offset=50., \n",
    "    random_state=0\n",
    ")\n",
    "topics = pd.DataFrame(word_dict)\n",
    "lda.fit(tfidf)\n",
    "\n",
    "\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "\n",
    "word_dict ={}\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "        top_features_ind = topic.argsort()[:-n_top_words - 1:-1]\n",
    "        top_features = [tf_feature_names[i] for i in top_features_ind]\n",
    "        word_dict['Topic'+str(topic_idx)] = top_features\n",
    "topics = pd.DataFrame(word_dict)\n",
    "print('\\n\\n LDA: \\n\\n',topics.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37898ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
